{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from datetime import datetime, timedelta\n",
    "from trim_image_xy import trim_image_xy\n",
    "import imageio\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a gif from frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a gif of the entire dataset, I start by creating image times accounting for the difference in gmt and mst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = sorted(glob.glob('../../data/class/full_images/*.png'), key=os.path.getmtime)\n",
    "image_times = [x.replace('../../data/class/full_images\\\\denvertraffic', '') for x in image_list]\n",
    "image_times = [x.replace('.png', '') for x in image_times]\n",
    "image_times = [x.replace('_', ':') for x in image_times]\n",
    "\n",
    "#change to datetime objects\n",
    "image_times = [datetime.strptime(x,\"%Y-%m-%d %H:%M:%S\") for x in image_times]\n",
    "\n",
    "#set times to MST from GMT\n",
    "diff_hours = timedelta(hours=-6)\n",
    "image_times_mst = [x + diff_hours for x in image_times]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the images are read in, cropped, labeled, and saved in a specified directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63543080555a442ba175199b02967d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2475), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_font_path = 'C:/Windows/Fonts/'\n",
    "image_path_input = '../../data/class/full_images/'\n",
    "image_path_output = '../../data/class/fulllengthgifframes/'\n",
    "\n",
    "for position, file in enumerate(tqdm(image_list)):\n",
    "    im1 = Image.open(file)\n",
    "    \n",
    "    #crop to focus area\n",
    "    im2 = im1.crop((500,0,1720,1080))\n",
    "    \n",
    "    #set a label of formatted datetime val\n",
    "    label = datetime.strftime(image_times_mst[position], \"%Y-%m-%d %I:%M %p\")\n",
    "    \n",
    "    #set label position, font, colror\n",
    "    label_position = (500, 25)\n",
    "    font = ImageFont.truetype(image_font_path + 'CALIBRI.ttf', size=24)\n",
    "    color = (0, 0, 0)\n",
    "    \n",
    "    #draw labels\n",
    "    draw = ImageDraw.Draw(im2)\n",
    "    draw.text(label_position, label, fill=color, font=font)\n",
    "    \n",
    "    #for sorting\n",
    "    image_name_output = 'a' + str(position) + '.png'\n",
    "\n",
    "    #save cropped images with time labels\n",
    "    im2.save(image_path_output + image_name_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the images are assembled into a gif. The ordering is determined by the creation time of the images. Through originally preserving the ordering of the files by their creation time, this ensures that the naming conventions dont interfere with the frame ordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d52745da62a457d9d7a7364564ce01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2475), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frames = []\n",
    "\n",
    "#get list of pngs to assemble into gif frames\n",
    "png_list = sorted(glob.glob(image_path_output + '*.png'), key=os.path.getmtime)\n",
    "\n",
    "#parse list and append to frames list\n",
    "for file in tqdm(png_list):\n",
    "    frames.append(imageio.imread(file))\n",
    "\n",
    "exportname = '../../data/class/gifs/denver_heartbeat_full_length.gif'\n",
    "\n",
    "#duration specifies display time per frame in seconds\n",
    "kargs = { 'duration': 0.03 }\n",
    "\n",
    "#construct gif\n",
    "imageio.mimsave(exportname, frames, 'GIF', **kargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Finally, I use ffmpeg in the command line to convert the file to a gif using two steps:\n",
    " \n",
    " Changing to the directory holding the .gif file\n",
    " \n",
    " ```cd C:\\Users\\Stuart\\Documents\\GitHub\\denver-traffic\\data\\class\\gifs```\n",
    " \n",
    "and then converting it to mp4 using a widely-accepted formatting\n",
    "\n",
    "```ffmpeg -i denver_heartbeat_full_length.gif -movflags faststart -pix_fmt yuv420p -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" denver_heartbeat_full_length.mp4```\n",
    "\n",
    "That leaves us with a vastly reduced filesize and an mp4 ready to go!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing a class for side by side viewing\n",
    "\n",
    "I wanted to display two images side-by-side. The left would be the traffic layer at a certain time and the right would be the traffic layer at exactly one week forward from that time. Below, some of the time series data from labeled pixel rgba values would be plotted. I wanted more experience using and creating classes so I put one together for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"../../data/class/gifs/denver_heartbeat_full_length.mp4\" controls  width=\"900\"  height=\"720\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('../../data/class/gifs/denver_heartbeat_full_length.mp4', height=720, width=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class traffic_image_transformer:\n",
    "    def __init__(self, filelist, filetype):\n",
    "        self.list1 = filelist\n",
    "        self.ftype = filetype\n",
    "    \n",
    "    def crop_images(self, crop_rectangle, output_filepath):\n",
    "        \"\"\"\n",
    "        Takes pixel left, upper, right, lower position tuple and an output path. \n",
    "        Writes out cropped images with same filetype as incoming ones. Then constructs and \n",
    "        returns a list with the filenames from the processed images.\n",
    "        \"\"\"\n",
    "        \n",
    "        if crop_rectangle and output_filepath != '':\n",
    "            for position, im in enumerate(tqdm(self.list1)):\n",
    "                im_temp = Image.open(im)\n",
    "                im_temp = im_temp.crop(crop_rectangle)\n",
    "                \n",
    "                #save as enumerated position with tags using same filetype as incoming image list\n",
    "                im_temp.save(output_filepath + str(position) + '_cropped' + self.ftype)\n",
    "                \n",
    "        else:\n",
    "            print('must provide both crop tuple and outgoing filepath for images. No transformations applied')\n",
    "        cropped_list = sorted(glob.glob(output_filepath + '*' + self.ftype), key=os.path.getmtime)\n",
    "        return cropped_list\n",
    "            \n",
    "            \n",
    "    def create_timestamps(self, hour_diff = 0, label_format = \"%Y-%m-%d %H:%M:%S\"):\n",
    "        \"\"\"creates a list with datetime values updated to local time for image list\"\"\"\n",
    "        \n",
    "        #keep only filename, strip alphabetic characters, replace file extension\n",
    "        image_times = [os.path.basename(x) for x in self.list1]\n",
    "        image_times = [re.sub('[a-zA-Z]', '', x) for x in image_times]\n",
    "        image_times = [x.replace(self.ftype, '').replace('_', ':').replace('.', '') for x in image_times]\n",
    "        \n",
    "        #convert to datetime given format and then update to local time using hour_diff\n",
    "        image_times = [datetime.strptime(x, label_format) for x in image_times]\n",
    "        diff_hours = timedelta(hours=hour_diff)\n",
    "        image_times_localized = [x + diff_hours for x in image_times]\n",
    "        \n",
    "        return image_times_localized\n",
    "    \n",
    "    def create_image_labels(self, datetime_list, label_format):\n",
    "        \"\"\"create label values using specified format and returns formatted values for labels\"\"\"\n",
    "        label_list = []\n",
    "        for position, val in datetime_list:\n",
    "            label_list.append(datetime.strftime(val, label_format))\n",
    "        return label_list\n",
    "\n",
    "\n",
    "    def resize_cropped_images(self, image_list = [], output_filepath = '', scale_by = 1):\n",
    "        \"\"\"\n",
    "        takes list of filepaths, gets image height and width and multiplies by scale factor. Resizes image using the\n",
    "        integer taken from the result and saves in output_filepath. Returns list of files in specfied directory after\n",
    "        running\n",
    "        \"\"\"\n",
    "        if image_list and output_filepath != '':\n",
    "            for position, file in enumerate(tqdm(image_list)):\n",
    "                im_temp = Image.open(file)\n",
    "                height,width = im_temp.size\n",
    "                r_height, r_width = (int(height * scale_by), int(width * scale_by))\n",
    "                im_out = im_temp.resize((r_height, r_width), Image.ANTIALIAS)\n",
    "                im_out.save(output_filepath + str(position) + \"_resized\" + self.ftype)\n",
    "\n",
    "        else:\n",
    "            print('no output path specified. No transformations applied')\n",
    "        resized_images = sorted(glob.glob(output_filepath + '*' + self.ftype), key=os.path.getmtime)\n",
    "        \n",
    "        return resized_images\n",
    "    \n",
    "    def create_lineplots(self, time_stamp_list, output_filepath, df_path, fields, styles):\n",
    "        \"\"\"\n",
    "        Reads in dataframe and creates plot, saves plot, and returns path of all saved plots\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(df_path, parse_dates=True, index_col= 'date_time')\n",
    "        for position, stamp in enumerate(tqdm(time_stamp_list)):\n",
    "            temp_frame = df[str(time_stamp_list[0]):str(time_stamp_list[position])]\n",
    "            plot = temp_frame.plot(y=fields,\n",
    "                                   style = styles,\n",
    "                                   yticks = ([0, 20, 40, 60, 80, 100]),\n",
    "                                   xlim = (time_stamp_list[0], time_stamp_list[-1]),\n",
    "                                   xticks = [],\n",
    "                                   figsize = (12,2)\n",
    "                                  )\n",
    "            plot.grid(axis='y', alpha = 0.3)\n",
    "            plot.set_ylabel(\"Pct Isolated Pixels\")\n",
    "            \n",
    "            fig = plot.get_figure()\n",
    "            fig.savefig(output_filepath + str(position) +'_plot' + self.ftype)\n",
    "            plt.close(fig)\n",
    "\n",
    "        plot_list = sorted(glob.glob(output_filepath + '*' + self.ftype), key=os.path.getmtime)\n",
    "        \n",
    "        return plot_list\n",
    "    \n",
    "    def gen_sbs_frames(self, num_frames, l_images, r_images, l_timestamps, r_timestamps, l_plots, r_plots, output_filepath):\n",
    "        \"\"\"\n",
    "        Draws side-by side traffic image on black background, labels appropriately, adds plots below each image\n",
    "        Exports frame, returns list of frames ordered by creation date upon completion\n",
    "        \"\"\"\n",
    "        for i in tqdm(range(0,num_frames,1)):\n",
    "            \n",
    "            im1 = Image.open(l_images[i])\n",
    "            im2 = Image.open(r_images[i])\n",
    "\n",
    "            #get labels for images\n",
    "            lab1 = l_timestamps[i]\n",
    "            lab2 = r_timestamps[i]\n",
    "    \n",
    "            #get plots for images\n",
    "            pl1 = Image.open(l_plots[i])\n",
    "            pl2 = Image.open(r_plots[i])\n",
    "    \n",
    "            # create background\n",
    "            bg = Image.new('RGB', (1920, 1080), color= (0,0,0))\n",
    "    \n",
    "            #add traffic images\n",
    "            bg.paste(im1, (30, 70))\n",
    "            bg.paste(im2, (975, 70))\n",
    "    \n",
    "            #add lineplots\n",
    "            bg.paste(pl1, (55, 900))\n",
    "            bg.paste(pl2, (1005, 900))\n",
    "    \n",
    "            # determine labels\n",
    "            draw = ImageDraw.Draw(bg)\n",
    "            image_font_path = 'C:/Windows/Fonts/'\n",
    "            font = ImageFont.truetype(image_font_path + 'CALIBRI.ttf', size=24)\n",
    "            label1 = datetime.strftime(l_timestamps[i], \"%Y-%m-%d %I:%M %p\")\n",
    "            label2 = datetime.strftime(r_timestamps[i], \"%Y-%m-%d %I:%M %p\")\n",
    "    \n",
    "            # draw label text\n",
    "            draw.text((375,45), label1, fill=(255,255,255), font = font, align = 'center' )\n",
    "            draw.text((1300,45), label2, fill=(255,255,255), font = font, align = 'center' )\n",
    "   \n",
    "            #generate day-of-week label\n",
    "            day1_label = datetime.strftime(l_timestamps[i], '%A')\n",
    "            day2_label = datetime.strftime(r_timestamps[i], '%A')\n",
    "    \n",
    "            #draw day-of-week value\n",
    "            draw.text((420,20), day1_label, fill=(255,255,255), font = font, align = 'center' )\n",
    "            draw.text((1340,20), day2_label, fill=(255,255,255), font = font, align = 'center' )\n",
    "\n",
    "            #export\n",
    "            frame_name = (output_filepath + str(i) + self.ftype)\n",
    "            bg.save(frame_name)\n",
    "            \n",
    "        frame_list = sorted(glob.glob(output_filepath + '*' + self.ftype), key=os.path.getmtime)\n",
    "        return frame_list\n",
    "    \n",
    "    def gif_from_frames(self, frame_file_list, output_filepath, frame_duration):\n",
    "        \"\"\"\n",
    "        Creates .gif file from frames at specified location\n",
    "        \"\"\"\n",
    "        frames = []\n",
    "        \n",
    "        #parse frame files and append to frames\n",
    "        for file in tqdm(frame_file_list):\n",
    "            frames.append(imageio.imread(file))\n",
    "\n",
    "        kargs = { 'duration': frame_duration }\n",
    "        \n",
    "        #create gif and print confirmation\n",
    "        imageio.mimsave(output_filepath, frames, 'GIF', **kargs)\n",
    "        print('Exported gif to ', output_filepath, ' successfully')\n",
    "        \n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block of global variables. \n",
    "Not great, I know. I'm working on finding a more elegant way to pass all these parameters. That's the fun in learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1_images = sorted(glob.glob('../../data/class/original/week1/*.png'), key=os.path.getmtime)\n",
    "week2_images = sorted(glob.glob('../../data/class/original/week2/*.png'), key=os.path.getmtime)\n",
    "\n",
    "extension = '.png'\n",
    "\n",
    "w1_cropped_path = '../../data/class/cropped/week1/'\n",
    "w2_cropped_path = '../../data/class/cropped/week2/'\n",
    "\n",
    "w1_resized_path = '../../data/class/resized/week1/'\n",
    "w2_resized_path = '../../data/class/resized/week2/'\n",
    "\n",
    "w1_plot_path = '../../data/class/plots/week1/'\n",
    "w2_plot_path = '../../data/class/plots/week2/'\n",
    "\n",
    "ts_path = '../../data/class/timeseries/full_series.csv'\n",
    "fields = ['moderate_plus_traffic_pct', 'traffic_green_pct']\n",
    "styles = ['tab:orange','tab:green']\n",
    "resize_by = (3/4)\n",
    "\n",
    "\n",
    "frame_path ='../../data/class/gifframes/'\n",
    "gif_path = '../../data/class/gifs/denver_heartbeat_side_by_side.gif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate frames with side by side images\n",
    "\n",
    "Now that the class is built and some parameters are set in the cell above, it's time to construct a gif of side by side, one week offset, images complete with a line plot that should grow across the bottom of the images showing groupings of traffic. These groupings were done manually using some sampled colors and are not the groupings identified by the k means clustering (yet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating class\n",
      "defining week1 timestamps\n",
      "cropping week1 images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6927984725ff4cfabaff643fa06dc8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194f5ab8224440dc8588ba9de5bbcc0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "creating week1 line plots\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d72097f373249e3965d3dac4c100ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py:1001: UserWarning: Attempting to set identical left == right == 737544.4396180556 results in singular transformations; automatically expanding.\n",
      "  ax.set_xlim(left, right)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "creating class\n",
      "defining week2 timestamps\n",
      "cropping week2 images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f260678a29954d35870bc3bc7c855882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "resizing week2 images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda4a5163c8e4066b21cbfebc2b86679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "creating week2 line plots\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb37d0c51ea54eaf9772636b2267b30e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\plotting\\_core.py:1001: UserWarning: Attempting to set identical left == right == 737551.354837963 results in singular transformations; automatically expanding.\n",
      "  ax.set_xlim(left, right)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "creating gif frames\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "980dc851c55a4dc2a2880e8700cf70cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "building gif\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32d5cb3a71846f08998a814a23b3e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=633), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-212042bfd9a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;31m#constructing gif file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'building gif'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[0mw1_im_processor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgif_from_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgif_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgif_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.025\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-645f8ce932c7>\u001b[0m in \u001b[0;36mgif_from_frames\u001b[1;34m(self, frame_file_list, output_filepath, frame_duration)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;31m#create gif and print confirmation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmimsave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_filepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GIF'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Exported gif to '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_filepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' successfully'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mmimwrite\u001b[1;34m(uri, ims, format, **kwargs)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[1;31m# Add image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m             \u001b[0mwritten\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\imageio\\core\\format.py\u001b[0m in \u001b[0;36mappend_data\u001b[1;34m(self, im, meta)\u001b[0m\n\u001b[0;32m    490\u001b[0m             \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;31m# Call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_append_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mset_meta_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\imageio\\plugins\\pillowmulti.py\u001b[0m in \u001b[0;36m_append_data\u001b[1;34m(self, im, meta)\u001b[0m\n\u001b[0;32m    115\u001b[0m                 \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mdispose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdispose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\imageio\\plugins\\pillowmulti.py\u001b[0m in \u001b[0;36madd_image\u001b[1;34m(self, im, duration, dispose)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt_subrectangle\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m             \u001b[0mim_rect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetSubRectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mim_pil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverToPIL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_rect\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt_quantizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopt_palette_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;31m# Get pallette - apparently, this is the 3d element of the header\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\imageio\\plugins\\pillowmulti.py\u001b[0m in \u001b[0;36mconverToPIL\u001b[1;34m(self, im, quantizer, palette_size)\u001b[0m\n\u001b[0;32m    369\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m                 \u001b[0mim_pil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim_pil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RGB\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m             \u001b[0mim_pil\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim_pil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpalette_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquantizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid value for quantizer: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mquantizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mquantize\u001b[1;34m(self, colors, method, kmeans, palette, dither)\u001b[0m\n\u001b[0;32m   1126\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1128\u001b[1;33m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#week 1\n",
    "#instantiate using the class\n",
    "print('creating class')\n",
    "w1_im_processor = traffic_image_transformer(week1_images, '.png')\n",
    "\n",
    "#store file timestamps\n",
    "print('defining week1 timestamps')\n",
    "w1_timestamps = w1_im_processor.create_timestamps(-6)\n",
    "\n",
    "#crop and store files\n",
    "print('cropping week1 images')\n",
    "w1_cropped_file_list = w1_im_processor.crop_images((500,0,1720,1080), w1_cropped_path)\n",
    "\n",
    "#resize images\n",
    "# print('resizing cropped week1 images')\n",
    "w1_resized_image_list = w1_im_processor.resize_cropped_images(w1_cropped_file_list, w1_resized_path, resize_by)\n",
    "\n",
    "#create plots for each image\n",
    "print('creating week1 line plots')\n",
    "w1_plots = w1_im_processor.create_lineplots(w1_timestamps, w1_plot_path, ts_path, fields, styles)\n",
    "\n",
    "#week 2\n",
    "# instantiate the class\n",
    "print('creating class')\n",
    "#633 due to occasional chrome crashing\n",
    "w2_im_processor = traffic_image_transformer(week2_images[:633], '.png')\n",
    "\n",
    "#store file timestamps\n",
    "print('defining week2 timestamps')\n",
    "w2_timestamps = w2_im_processor.create_timestamps(-6)\n",
    "\n",
    "#crop and store files\n",
    "print('cropping week2 images')\n",
    "w2_cropped_file_list = w2_im_processor.crop_images((500,0,1720,1080), w2_cropped_path)\n",
    "\n",
    "#resize images\n",
    "print('resizing week2 images')\n",
    "w2_resized_image_list = w2_im_processor.resize_cropped_images(w2_cropped_file_list, w2_resized_path, resize_by)\n",
    "\n",
    "#create plots\n",
    "print('creating week2 line plots')\n",
    "w2_plots = w2_im_processor.create_lineplots(w2_timestamps, w2_plot_path, ts_path, fields, styles)\n",
    "\n",
    "\n",
    "#create gif frames\n",
    "print('creating gif frames')\n",
    "gif_frames = w1_im_processor.gen_sbs_frames(633, #how many frames to make\n",
    "                                            w1_resized_image_list, w2_resized_image_list, #left and right image files\n",
    "                                            w1_timestamps, w2_timestamps, #left and right timestamps\n",
    "                                            w1_plots, w2_plots, #left and right lineplots\n",
    "                                            frame_path) #destination for frames\n",
    "#constructing gif file\n",
    "print('building gif')\n",
    "w1_im_processor.gif_from_frames(gif_frames, gif_path, 0.025)\n",
    "\n",
    "\n",
    "# cleanup the intermediate files: cropped images, resized images, plots, frames\n",
    "print('Removing intermediate files')\n",
    "for i in glob.glob(w1_cropped_path + \"*\"):\n",
    "    os.remove(i)\n",
    "\n",
    "for i in glob.glob(w2_cropped_path + \"*\"):\n",
    "    os.remove(i)\n",
    "    \n",
    "for i in glob.glob(w1_resized_path + \"*\"):\n",
    "    os.remove(i)\n",
    "    \n",
    "for i in glob.glob(w2_resized_path + \"*\"):\n",
    "    os.remove(i)\n",
    "    \n",
    "for i in glob.glob(w1_plot_path + \"*\"):\n",
    "    os.remove(i)\n",
    "    \n",
    "for i in glob.glob(w2_plot_path + \"*\"):\n",
    "    os.remove(i)\n",
    "\n",
    "for i in glob.glob(frame_path + \"*\"):\n",
    "    os.remove(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting .gif to .mp4\n",
    "\n",
    "Next, I use ffmpeg in the command line to convert the file to a gif using two steps. This is just like before:\n",
    " \n",
    " Changing to the directory holding the .gif file\n",
    " \n",
    " ```cd C:\\Users\\Stuart\\Documents\\GitHub\\denver-traffic\\data\\class\\gifs```\n",
    " \n",
    "and then converting it to mp4 using a widely-accepted formatting\n",
    "\n",
    "```ffmpeg -i denver_heartbeat_side_by_side.gif -movflags faststart -pix_fmt yuv420p -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" denver_heartbeat_side_by_side.mp4\n",
    "```\n",
    "\n",
    "This cuts down on the filesize by a huge factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"../../data/class/gifs/denver_heartbeat_side_by_side.mp4\" controls  width=\"900\"  height=\"500\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"../../data/class/gifs/denver_heartbeat_side_by_side.mp4\", height=500, width=900)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
